# Challenge_TelecomX_2
# üìä An√°lisis de Cancelaci√≥n de Clientes (Churn) en TelecomX

Este repositorio contiene un an√°lisis completo para predecir la cancelaci√≥n (*churn*) de clientes de la empresa ficticia **TelecomX**, utilizando un enfoque de **Machine Learning** con Python.  
El proyecto incluye **an√°lisis exploratorio de datos (EDA)**, **preprocesamiento**, **modelado**, **optimizaci√≥n de hiperpar√°metros** y **evaluaci√≥n de modelos**.

---

## üìÇ Contenido del Proyecto

1. **Extracci√≥n y Preparaci√≥n de Datos**  
   - Carga del dataset (`datos.csv`).  
   - Limpieza y eliminaci√≥n de variables irrelevantes.  

2. **An√°lisis Exploratorio (EDA)**  
   - Distribuci√≥n de `Churn` y variables categ√≥ricas.  
   - An√°lisis de variables num√©ricas (`tenure`, `Charges.Monthly`, `Cuentas_diarias`, etc.).  

3. **Ingenier√≠a de Caracter√≠sticas**  
   - Creaci√≥n de `Cuentas_diarias` como m√©trica robusta de gasto.  
   - Eliminaci√≥n de variables redundantes y codificaci√≥n *One-Hot*.  
   - An√°lisis de correlaci√≥n y selecci√≥n de features relevantes.  

4. **Balanceo de Clases**  
   - Uso de **SMOTE** para manejar el desbalance (73.46% permanece vs 26.54% cancela).  

5. **Modelado Inicial**  
   - Modelo base: **Regresi√≥n Log√≠stica**.  

6. **Comparaci√≥n de Modelos**  
   - **√Årbol de Decisi√≥n**  
   - **Random Forest**  
   - **KNN**  

7. **Importancia de Variables**  
   - An√°lisis con Random Forest para ranking de features.  

8. **Selecci√≥n de Variables y Validaci√≥n Cruzada**  
   - Evaluaci√≥n con distintas cantidades de features.  

9. **Optimizaci√≥n de Hiperpar√°metros**  
   - **GridSearchCV** para maximizar *F1 Score*.  

10. **Evaluaci√≥n Final**  
    - M√©tricas de rendimiento en datos de test.  
    - Matrices de confusi√≥n y m√©tricas detalladas.

---

## üõ†Ô∏è Tecnolog√≠as y Librer√≠as Usadas

- **Python 3.10+**
- **Pandas** ‚Äî Manipulaci√≥n y limpieza de datos.
- **NumPy** ‚Äî Operaciones num√©ricas.
- **Matplotlib / Seaborn** ‚Äî Visualizaci√≥n de datos.
- **Scikit-learn** ‚Äî Modelado, m√©tricas, validaci√≥n cruzada.
- **Imbalanced-learn (SMOTE)** ‚Äî Balanceo de clases.
- **Google Colab** ‚Äî Entorno de ejecuci√≥n.

---

## üìä Resultados Clave

- **Random Forest** result√≥ ser el modelo con mejor equilibrio entre *Recall* y *Precision*.  
- Mantener entre **20 y 22 variables** optimiza el rendimiento sin p√©rdida significativa.  
- El *GridSearchCV* permiti√≥ mejorar las m√©tricas optimizando la profundidad y n√∫mero de estimadores.  

---

## üöÄ Ejecuci√≥n del Notebook

1. Clonar este repositorio.
   
2. Abrir en Google Colab.

3. Subir el archivo datos.csv al entorno de Colab.

4. Ejecutar las celdas en orden.

---

## ‚úçÔ∏è Autor

Daniel Medina
